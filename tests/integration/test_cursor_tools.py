#!/usr/bin/env python3
"""
–¢–µ—Å—Ç tool calling —á–µ—Ä–µ–∑ LLM PII Proxy
"""

import json
import asyncio
import httpx

async def test_tool_calling():
    """–¢–µ—Å—Ç –≤—ã–∑–æ–≤–∞ tools —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
    
    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∫–æ—Ç–æ—Ä—ã–π –î–û–õ–ñ–ï–ù –≤—ã–∑–≤–∞—Ç—å tool
    test_request = {
        "model": "gpt-4.1",
        "messages": [
            {
                "role": "user", 
                "content": "–ü—Ä–æ—á–∏—Ç–∞–π —Ñ–∞–π–ª llm_pii_proxy/main.py –∏ —Å–∫–∞–∂–∏ —á—Ç–æ –≤ –Ω–µ–º"
            }
        ],
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "read_file",
                    "description": "Read a file",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "filename": {
                                "type": "string",
                                "description": "Path to file"
                            }
                        },
                        "required": ["filename"]
                    }
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0.0,
        "stream": False
    }
    
    print("üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —Å tool calling...")
    print(f"üì§ REQUEST: {json.dumps(test_request, indent=2, ensure_ascii=False)}")
    
    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                "http://192.168.0.182:8000/v1/chat/completions",
                json=test_request,
                headers={"Content-Type": "application/json"},
                timeout=30.0
            )
            
            print(f"üì® RESPONSE STATUS: {response.status_code}")
            print(f"üì® RESPONSE HEADERS: {dict(response.headers)}")
            
            if response.status_code == 200:
                response_data = response.json()
                print(f"üì® RESPONSE BODY: {json.dumps(response_data, indent=2, ensure_ascii=False)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º tool_calls
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    message = response_data["choices"][0].get("message", {})
                    if "tool_calls" in message and message["tool_calls"]:
                        print(f"üîß –ù–ê–ô–î–ï–ù–´ TOOL CALLS: {len(message['tool_calls'])}")
                        for i, tc in enumerate(message["tool_calls"]):
                            print(f"   Tool {i+1}: {tc.get('function', {}).get('name', 'unknown')}")
                        return True
                    else:
                        print("‚ùå –ù–ï–¢ TOOL CALLS –≤ –æ—Ç–≤–µ—Ç–µ!")
                        return False
                else:
                    print("‚ùå –ù–ï–¢ CHOICES –≤ –æ—Ç–≤–µ—Ç–µ!")
                    return False
            else:
                print(f"‚ùå –û–®–ò–ë–ö–ê: {response.status_code}")
                print(f"‚ùå BODY: {response.text}")
                return False
                
        except Exception as e:
            print(f"üí• EXCEPTION: {e}")
            return False

if __name__ == "__main__":
    result = asyncio.run(test_tool_calling())
    if result:
        print("‚úÖ TOOL CALLING –†–ê–ë–û–¢–ê–ï–¢!")
    else:
        print("‚ùå TOOL CALLING –ù–ï –†–ê–ë–û–¢–ê–ï–¢!") 