#!/usr/bin/env python3
"""
üß™ –¢–ï–°–¢ PII –° –†–ï–ê–õ–¨–ù–û–ô LLM
–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ PII –∑–∞—â–∏—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ Azure OpenAI
"""

import asyncio
import json
import os
from typing import Dict, Any

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../..'))

from llm_pii_proxy.services.llm_service import LLMService
from llm_pii_proxy.providers.azure_provider import AzureOpenAIProvider
from llm_pii_proxy.security.pii_gateway import AsyncPIISecurityGateway
from llm_pii_proxy.config.settings import Settings
from llm_pii_proxy.core.models import ChatRequest, ChatMessage

async def test_pii_with_real_llm_simple():
    """–¢–µ—Å—Ç PII —Å —Ä–µ–∞–ª—å–Ω—ã–º LLM - –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å"""
    print("üß™ –¢–ï–°–¢ 1: PII —Å —Ä–µ–∞–ª—å–Ω—ã–º LLM - –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å")
    print("=" * 60)
    
    # –í–∫–ª—é—á–∞–µ–º PII –∑–∞—â–∏—Ç—É
    os.environ['PII_PROTECTION_ENABLED'] = 'true'
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å –≤–∫–ª—é—á–µ–Ω–Ω–æ–π PII –∑–∞—â–∏—Ç–æ–π
        settings = Settings()
        azure_provider = AzureOpenAIProvider()
        pii_gateway = AsyncPIISecurityGateway()
        llm_service = LLMService(azure_provider, pii_gateway)
        
        print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        print(f"   PII –∑–∞—â–∏—Ç–∞: {settings.pii_protection_enabled}")
        print(f"   Debug —Ä–µ–∂–∏–º: {settings.pii_proxy_debug}")
        print(f"   Azure endpoint: {settings.azure_openai_endpoint}")
        print(f"   Azure model: {settings.azure_completions_model}")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å PII –¥–∞–Ω–Ω—ã–º–∏
        request = ChatRequest(
            model="gpt-4.1",
            messages=[
                ChatMessage(
                    role="user", 
                    content="–ü—Ä–∏–≤–µ—Ç! –ú–æ–π AWS –∫–ª—é—á AKIA1234567890EXAMPLE –∏ IP –∞–¥—Ä–µ—Å 192.168.1.100. –ú–æ–∂–µ—à—å —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ-—Ç–æ –æ–± —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö?"
                )
            ],
            pii_protection=True,
            max_tokens=100
        )
        
        print(f"\nüìù –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {request.messages[0].content}")
        print(f"   PII –∑–∞—â–∏—Ç–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–∞: {request.pii_protection}")
        
        print(f"\nüöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ —Ä–µ–∞–ª—å–Ω–æ–π LLM —Å PII –∑–∞—â–∏—Ç–æ–π...")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = await llm_service.process_chat_request(request)
        
        print(f"\n‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω!")
        print(f"   ID –æ—Ç–≤–µ—Ç–∞: {response.id}")
        print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
        
        response_content = response.choices[0]['message']['content']
        print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞:")
        print(f"   {response_content}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ PII –¥–∞–Ω–Ω—ã–µ (–¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω—ã)
        has_original_aws = "AKIA1234567890EXAMPLE" in response_content
        has_original_ip = "192.168.1.100" in response_content
        has_masked_data = "<aws_key_" in response_content or "<ip_address_" in response_content
        
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞:")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π AWS –∫–ª—é—á: {has_original_aws}")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π IP: {has_original_ip}")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {has_masked_data}")
        
        if has_original_aws or has_original_ip:
            print(f"   ‚úÖ PII –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            success = True
        elif has_masked_data:
            print(f"   ‚ö†Ô∏è –í –æ—Ç–≤–µ—Ç–µ –æ—Å—Ç–∞–ª–∏—Å—å –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            success = False
        else:
            print(f"   ‚ÑπÔ∏è LLM –Ω–µ —É–ø–æ–º—è–Ω—É–ª PII –¥–∞–Ω–Ω—ã–µ –≤ –æ—Ç–≤–µ—Ç–µ")
            success = True  # –≠—Ç–æ —Ç–æ–∂–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        
        return success
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å —Ä–µ–∞–ª—å–Ω–æ–π LLM: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_pii_with_real_llm_tools():
    """–¢–µ—Å—Ç PII —Å —Ä–µ–∞–ª—å–Ω—ã–º LLM –∏ tool calls"""
    print("\nüß™ –¢–ï–°–¢ 2: PII —Å —Ä–µ–∞–ª—å–Ω—ã–º LLM –∏ tool calls")
    print("=" * 60)
    
    # –í–∫–ª—é—á–∞–µ–º PII –∑–∞—â–∏—Ç—É
    os.environ['PII_PROTECTION_ENABLED'] = 'true'
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        settings = Settings()
        azure_provider = AzureOpenAIProvider()
        pii_gateway = AsyncPIISecurityGateway()
        llm_service = LLMService(azure_provider, pii_gateway)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å PII –¥–∞–Ω–Ω—ã–º–∏ –∏ tools
        request = ChatRequest(
            model="gpt-4.1",
            messages=[
                ChatMessage(
                    role="user", 
                    content="–°–æ–∑–¥–∞–π —Ñ–∞–π–ª credentials.txt —Å –º–æ–∏–º AWS –∫–ª—é—á–æ–º AKIA1234567890EXAMPLE"
                )
            ],
            pii_protection=True,
            max_tokens=150,
            tools=[
                {
                    "type": "function",
                    "function": {
                        "name": "create_file",
                        "description": "Create a file with given content",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "filename": {"type": "string"},
                                "content": {"type": "string"}
                            },
                            "required": ["filename", "content"]
                        }
                    }
                }
            ]
        )
        
        print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {request.messages[0].content}")
        print(f"   Tools: {len(request.tools)} tool(s)")
        
        print(f"\nüöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —Å tools –∫ —Ä–µ–∞–ª—å–Ω–æ–π LLM...")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = await llm_service.process_chat_request(request)
        
        print(f"\n‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω!")
        print(f"   ID –æ—Ç–≤–µ—Ç–∞: {response.id}")
        print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
        choice = response.choices[0]
        if choice.get('message', {}).get('tool_calls'):
            print(f"   üîß Tool calls –Ω–∞–π–¥–µ–Ω—ã: {len(choice['message']['tool_calls'])}")
            
            for i, tool_call in enumerate(choice['message']['tool_calls']):
                print(f"\n   Tool call {i+1}:")
                print(f"     Function: {tool_call['function']['name']}")
                
                args = tool_call['function']['arguments']
                if isinstance(args, str):
                    args_dict = json.loads(args)
                else:
                    args_dict = args
                
                print(f"     Arguments: {json.dumps(args_dict, indent=6, ensure_ascii=False)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ AWS –∫–ª—é—á –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω –≤ tool call
                args_str = json.dumps(args_dict)
                has_original_aws = "AKIA1234567890EXAMPLE" in args_str
                has_masked_aws = "<aws_key_" in args_str
                
                print(f"     üîç –ê–Ω–∞–ª–∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤:")
                print(f"       –°–æ–¥–µ—Ä–∂–∏—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π AWS –∫–ª—é—á: {has_original_aws}")
                print(f"       –°–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AWS –∫–ª—é—á: {has_masked_aws}")
                
                if has_original_aws:
                    print(f"       ‚úÖ AWS –∫–ª—é—á –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω –≤ tool call")
                    success = True
                elif has_masked_aws:
                    print(f"       ‚ùå AWS –∫–ª—é—á –æ—Å—Ç–∞–ª—Å—è –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤ tool call")
                    success = False
                else:
                    print(f"       ‚ö†Ô∏è AWS –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ tool call –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö")
                    success = False
        else:
            print(f"   üìù –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç (–±–µ–∑ tool calls)")
            content = choice.get('message', {}).get('content', '')
            print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç: {content}")
            
            # –ï—Å–ª–∏ –Ω–µ—Ç tool calls, –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            has_original_aws = "AKIA1234567890EXAMPLE" in content
            success = has_original_aws
        
        return success
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ tools —Å —Ä–µ–∞–ª—å–Ω–æ–π LLM: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_pii_disabled_vs_enabled():
    """–¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è PII –æ—Ç–∫–ª—é—á–µ–Ω vs –≤–∫–ª—é—á–µ–Ω"""
    print("\nüß™ –¢–ï–°–¢ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ PII –æ—Ç–∫–ª—é—á–µ–Ω vs –≤–∫–ª—é—á–µ–Ω")
    print("=" * 60)
    
    test_message = "–ú–æ–π AWS –∫–ª—é—á AKIA1234567890EXAMPLE"
    
    try:
        # –¢–µ—Å—Ç 1: PII –æ—Ç–∫–ª—é—á–µ–Ω
        print(f"üî¥ –¢–µ—Å—Ç —Å –û–¢–ö–õ–Æ–ß–ï–ù–ù–û–ô PII –∑–∞—â–∏—Ç–æ–π:")
        os.environ['PII_PROTECTION_ENABLED'] = 'false'
        
        settings_off = Settings()
        azure_provider_off = AzureOpenAIProvider()
        pii_gateway_off = AsyncPIISecurityGateway()
        llm_service_off = LLMService(azure_provider_off, pii_gateway_off)
        
        request_off = ChatRequest(
            model="gpt-4.1",
            messages=[ChatMessage(role="user", content=test_message)],
            pii_protection=True,
            max_tokens=50
        )
        
        print(f"   Settings PII enabled: {settings_off.pii_protection_enabled}")
        print(f"   LLMService PII enabled: {llm_service_off.pii_enabled}")
        
        # –¢–µ—Å—Ç 2: PII –≤–∫–ª—é—á–µ–Ω
        print(f"\nüü¢ –¢–µ—Å—Ç —Å –í–ö–õ–Æ–ß–ï–ù–ù–û–ô PII –∑–∞—â–∏—Ç–æ–π:")
        os.environ['PII_PROTECTION_ENABLED'] = 'true'
        
        settings_on = Settings()
        azure_provider_on = AzureOpenAIProvider()
        pii_gateway_on = AsyncPIISecurityGateway()
        llm_service_on = LLMService(azure_provider_on, pii_gateway_on)
        
        request_on = ChatRequest(
            model="gpt-4.1",
            messages=[ChatMessage(role="user", content=test_message)],
            pii_protection=True,
            max_tokens=50
        )
        
        print(f"   Settings PII enabled: {settings_on.pii_protection_enabled}")
        print(f"   LLMService PII enabled: {llm_service_on.pii_enabled}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è
        config_different = (
            settings_off.pii_protection_enabled != settings_on.pii_protection_enabled or
            llm_service_off.pii_enabled != llm_service_on.pii_enabled
        )
        
        if config_different:
            print(f"\n‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è")
            return True
        else:
            print(f"\n‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è")
            return False
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {e}")
        return False

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PII –° –†–ï–ê–õ–¨–ù–û–ô LLM")
    print("=" * 70)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
    original_pii_setting = os.getenv('PII_PROTECTION_ENABLED')
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
        tests = [
            test_pii_disabled_vs_enabled,
            test_pii_with_real_llm_simple,
            test_pii_with_real_llm_tools
        ]
        
        results = []
        for test in tests:
            try:
                result = await test()
                results.append(result)
            except Exception as e:
                print(f"‚ùå –¢–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {e}")
                results.append(False)
        
        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        print("\n" + "=" * 70)
        print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
        print("=" * 70)
        
        passed = sum(results)
        total = len(results)
        
        print(f"–ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}/{total}")
        print(f"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {passed/total*100:.1f}%")
        
        if passed == total:
            print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
            print("‚úÖ PII –∑–∞—â–∏—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å —Ä–µ–∞–ª—å–Ω–æ–π LLM")
        else:
            print("‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´")
            print("‚ùå PII –∑–∞—â–∏—Ç–∞ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
        
        return passed == total
        
    finally:
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
        if original_pii_setting is not None:
            os.environ['PII_PROTECTION_ENABLED'] = original_pii_setting
        else:
            os.environ.pop('PII_PROTECTION_ENABLED', None)

if __name__ == "__main__":
    asyncio.run(main()) 