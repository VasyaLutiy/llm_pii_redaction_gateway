#!/usr/bin/env python3
"""
üß™ –¢–ï–°–¢ PII –° –†–ï–ê–õ–¨–ù–´–ú LLM –°–ï–†–í–ò–°–û–ú
–ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é PII —Å LLMService
"""

import asyncio
import json
import os
from typing import Dict, Any

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../..'))

from llm_pii_proxy.services.llm_service import LLMService
from llm_pii_proxy.providers.azure_provider import AzureOpenAIProvider
from llm_pii_proxy.security.pii_gateway import AsyncPIISecurityGateway
from llm_pii_proxy.config.settings import Settings
from llm_pii_proxy.core.models import ChatRequest, ChatMessage

async def test_llm_service_without_pii():
    """–¢–µ—Å—Ç LLM —Å–µ—Ä–≤–∏—Å–∞ –±–µ–∑ PII (—Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ)"""
    print("üß™ –¢–ï–°–¢ 1: LLM —Å–µ—Ä–≤–∏—Å –ë–ï–ó PII –∑–∞—â–∏—Ç—ã")
    print("=" * 50)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    azure_provider = AzureOpenAIProvider()  # –ù–µ –ø–µ—Ä–µ–¥–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    pii_gateway = AsyncPIISecurityGateway()
    llm_service = LLMService(azure_provider, pii_gateway)
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å PII –¥–∞–Ω–Ω—ã–º–∏
    request = ChatRequest(
        model="gpt-4.1",
        messages=[
            ChatMessage(
                role="user", 
                content="–ü—Ä–∏–≤–µ—Ç! –ú–æ–π AWS –∫–ª—é—á AKIA1234567890EXAMPLE –∏ –ø–∞—Ä–æ–ª—å mySecret123"
            )
        ],
        pii_protection=True,  # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∑–∞—â–∏—Ç—É, –Ω–æ –æ–Ω–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ
        max_tokens=50
    )
    
    print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
    print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {request.messages[0].content}")
    print(f"   PII –∑–∞—â–∏—Ç–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–∞: {request.pii_protection}")
    print(f"   –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è PII_PROTECTION_ENABLED: {os.getenv('PII_PROTECTION_ENABLED', 'false')}")
    
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = await llm_service.process_chat_request(request)
        
        print(f"\n‚úÖ –ó–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!")
        print(f"   ID –æ—Ç–≤–µ—Ç–∞: {response.id}")
        print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
        print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞: {response.choices[0]['message']['content'][:100]}...")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return False

async def test_llm_service_with_pii_enabled():
    """–¢–µ—Å—Ç LLM —Å–µ—Ä–≤–∏—Å–∞ —Å –≤–∫–ª—é—á–µ–Ω–Ω–æ–π PII –∑–∞—â–∏—Ç–æ–π"""
    print("\nüß™ –¢–ï–°–¢ 2: LLM —Å–µ—Ä–≤–∏—Å –° PII –∑–∞—â–∏—Ç–æ–π")
    print("=" * 50)
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–∫–ª—é—á–∞–µ–º PII –∑–∞—â–∏—Ç—É
    original_pii_setting = os.getenv('PII_PROTECTION_ENABLED', 'false')
    os.environ['PII_PROTECTION_ENABLED'] = 'true'
    
    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        azure_provider = AzureOpenAIProvider()  # –ù–µ –ø–µ—Ä–µ–¥–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        pii_gateway = AsyncPIISecurityGateway()
        llm_service = LLMService(azure_provider, pii_gateway)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å PII –¥–∞–Ω–Ω—ã–º–∏
        request = ChatRequest(
            model="gpt-4.1",
            messages=[
                ChatMessage(
                    role="user", 
                    content="–ü—Ä–∏–≤–µ—Ç! –ú–æ–π AWS –∫–ª—é—á AKIA1234567890EXAMPLE –∏ IP –∞–¥—Ä–µ—Å 192.168.1.100"
                )
            ],
            pii_protection=True,
            max_tokens=50
        )
        
        print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {request.messages[0].content}")
        print(f"   PII –∑–∞—â–∏—Ç–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–∞: {request.pii_protection}")
        print(f"   –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è PII_PROTECTION_ENABLED: {os.getenv('PII_PROTECTION_ENABLED', 'false')}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = await llm_service.process_chat_request(request)
        
        print(f"\n‚úÖ –ó–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Å PII –∑–∞—â–∏—Ç–æ–π!")
        print(f"   ID –æ—Ç–≤–µ—Ç–∞: {response.id}")
        print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
        print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞: {response.choices[0]['message']['content'][:200]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –æ—Ç–≤–µ—Ç–µ –Ω–µ—Ç –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω—ã)
        response_content = response.choices[0]['message']['content']
        if '<aws_key_' in response_content or '<ip_address_' in response_content:
            print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í –æ—Ç–≤–µ—Ç–µ –æ—Å—Ç–∞–ª–∏—Å—å –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ!")
            print(f"   –≠—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É —Å –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ–º")
        else:
            print(f"‚úÖ –û—Ç–≤–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ —Å PII: {e}")
        return False
    
    finally:
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
        os.environ['PII_PROTECTION_ENABLED'] = original_pii_setting

async def test_llm_service_with_tools_and_pii():
    """–¢–µ—Å—Ç LLM —Å–µ—Ä–≤–∏—Å–∞ —Å tools –∏ PII –∑–∞—â–∏—Ç–æ–π"""
    print("\nüß™ –¢–ï–°–¢ 3: LLM —Å–µ—Ä–≤–∏—Å —Å Tools –∏ PII –∑–∞—â–∏—Ç–æ–π")
    print("=" * 50)
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–∫–ª—é—á–∞–µ–º PII –∑–∞—â–∏—Ç—É
    original_pii_setting = os.getenv('PII_PROTECTION_ENABLED', 'false')
    os.environ['PII_PROTECTION_ENABLED'] = 'true'
    
    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        azure_provider = AzureOpenAIProvider()  # –ù–µ –ø–µ—Ä–µ–¥–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        pii_gateway = AsyncPIISecurityGateway()
        llm_service = LLMService(azure_provider, pii_gateway)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å PII –¥–∞–Ω–Ω—ã–º–∏ –∏ tools
        request = ChatRequest(
            model="gpt-4.1",
            messages=[
                ChatMessage(
                    role="user", 
                    content="–°–æ–∑–¥–∞–π —Ñ–∞–π–ª —Å –º–æ–∏–º AWS –∫–ª—é—á–æ–º AKIA1234567890EXAMPLE"
                )
            ],
            pii_protection=True,
            max_tokens=150,
            tools=[
                {
                    "type": "function",
                    "function": {
                        "name": "create_file",
                        "description": "Create a file with given content",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "filename": {"type": "string"},
                                "content": {"type": "string"}
                            },
                            "required": ["filename", "content"]
                        }
                    }
                }
            ]
        )
        
        print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {request.messages[0].content}")
        print(f"   PII –∑–∞—â–∏—Ç–∞: {request.pii_protection}")
        print(f"   Tools: {len(request.tools)} tool(s)")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = await llm_service.process_chat_request(request)
        
        print(f"\n‚úÖ –ó–∞–ø—Ä–æ—Å —Å tools —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!")
        print(f"   ID –æ—Ç–≤–µ—Ç–∞: {response.id}")
        print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
        choice = response.choices[0]
        if choice.get('message', {}).get('tool_calls'):
            print(f"   üîß Tool calls –Ω–∞–π–¥–µ–Ω—ã: {len(choice['message']['tool_calls'])}")
            
            for i, tool_call in enumerate(choice['message']['tool_calls']):
                print(f"   Tool {i+1}: {tool_call['function']['name']}")
                args = tool_call['function']['arguments']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω—ã
                if isinstance(args, str):
                    args_dict = json.loads(args)
                else:
                    args_dict = args
                
                print(f"   –ê—Ä–≥—É–º–µ–Ω—Ç—ã: {args_dict}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ AWS –∫–ª—é—á –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω
                args_str = json.dumps(args_dict)
                if 'AKIA1234567890EXAMPLE' in args_str:
                    print(f"   ‚úÖ AWS –∫–ª—é—á –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–µ–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω –≤ tool call")
                elif '<aws_key_' in args_str:
                    print(f"   ‚ö†Ô∏è AWS –∫–ª—é—á –æ—Å—Ç–∞–ª—Å—è –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤ tool call")
                else:
                    print(f"   ‚ÑπÔ∏è AWS –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ tool call –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö")
        else:
            print(f"   üìù –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç (–±–µ–∑ tool calls)")
            content = choice.get('message', {}).get('content', '')
            print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç: {content[:200]}...")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ —Å tools –∏ PII: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
        os.environ['PII_PROTECTION_ENABLED'] = original_pii_setting

async def test_pii_configuration():
    """–¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PII"""
    print("\nüß™ –¢–ï–°–¢ 4: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è PII")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_files = [
        "llm_pii_proxy/config/pii_patterns.yaml",
        "azure.env"
    ]
    
    for config_file in config_files:
        if os.path.exists(config_file):
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω: {config_file}")
        else:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω: {config_file}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    env_vars = [
        'AZURE_OPENAI_API_KEY',
        'AZURE_OPENAI_ENDPOINT',
        'PII_PROTECTION_ENABLED',
        'PII_PROXY_DEBUG'
    ]
    
    print(f"\nüìã –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    for var in env_vars:
        value = os.getenv(var, '–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù–ê')
        if var.endswith('_KEY'):
            # –°–∫—Ä—ã–≤–∞–µ–º –∫–ª—é—á–∏
            display_value = f"{value[:10]}..." if len(value) > 10 else value
        else:
            display_value = value
        print(f"   {var}: {display_value}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    try:
        settings = Settings()
        print(f"\n‚úÖ Settings —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
        azure_provider = AzureOpenAIProvider()  # –ù–µ –ø–µ—Ä–µ–¥–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        print(f"‚úÖ AzureOpenAIProvider —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        pii_gateway = AsyncPIISecurityGateway()
        print(f"‚úÖ AsyncPIISecurityGateway —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        llm_service = LLMService(azure_provider, pii_gateway)
        print(f"‚úÖ LLMService —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
        return False

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PII –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –° LLM –°–ï–†–í–ò–°–û–ú")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    tests = [
        test_pii_configuration,
        test_llm_service_without_pii,
        test_llm_service_with_pii_enabled,
        test_llm_service_with_tools_and_pii
    ]
    
    results = []
    for test in tests:
        try:
            result = await test()
            results.append(result)
        except Exception as e:
            print(f"‚ùå –¢–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {e}")
            results.append(False)
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    passed = sum(results)
    total = len(results)
    
    print(f"–ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}/{total}")
    print(f"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {passed/total*100:.1f}%")
    
    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
    else:
        print("‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´")
    
    return passed == total

if __name__ == "__main__":
    asyncio.run(main()) 